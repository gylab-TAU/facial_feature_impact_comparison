[DATASET]
filters=["phase_perc_size"]
image_size = [256,256]
post_crop_im_size = 224
dataset_means = [0.5, 0.5, 0.5]
dataset_stds = [0.5, 0.5, 0.5]
; dataset_means = [0.485, 0.456, 0.406]
; dataset_stds = [0.229, 0.224, 0.225]
# set this dir to the dataset dir
; raw_dataset_path = ../../datasets/images_faces/images_only
#raw_dataset_path = ../../datasets/processed/vggface2_discriminator min_size=400_num-classes_1250_{'train': 300, 'val': 50, 'test': 50}_cropsgood_cl
raw_dataset_path = /home/administrator/experiments/familiarity/dataset/pretraining_dataset
crop_scale={"max": 1.0, "min": 1.0}
processed_dataset_root = /home/administrator/experiments/familiarity/dataset/processed_pretraining_dataset/
class_filter_dataset_dir = phase_perc_size
dataset_name = pretraining
phase_size_dict = {"train":0.7, "val": 0.2, "test":0.1}

[MODELLING]
feature_parallelized_architectures = ["VGG", "vgg11", "vgg11_bn", "vgg13", "vgg13_bn", "vgg16", "vgg16_bn",
    "vgg19_bn", "vgg19", "AlexNet", "alexnet"]
#architecture = wide_resnet50_2
architecture = vgg16
# If you want to start from the middle of training, set this to the epoch you wish to start from (it will load start_epoch-1 from the dir)
start_epoch = 0
end_epoch = 300
is_pretrained = False
num_classes = 8749
criterion_name = CrossEntropyLoss
criterion_params = {}
batch_size=128
workers=4
performance_test=LFW_TEST
; performance_test=None
perf_threshold=0.99
#each #num_epochs_to_test we make a LFW test
num_epochs_to_test=10
num_batches_per_epoch_limit=1000
logs_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/${MODELLING:architecture}/results/
; checkpoint_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/${MODELLING:architecture}/models/149.pth

[OPTIMIZING]
optimizer = SGD
optimizer_params = {
    "lr": 0.01,
    "momentum": 0.9,
    "weight_decay": 5e-4}
;     "betas": [0.9, 0.9],

;     "nesterov": true}
lr_scheduler = StepLR
lr_scheduler_params = {
    "step_size": 100,
    "gamma": 0.1}

[GENERAL]
root_dir = /home/administrator/experiments/familiarity/
#change to name of experiment (the output folder will be created accordingly)
experiment_name = pretraining
#experiment_name = dlib_discriminator
#experiment_name = high_importance_features_full_dataset

[LFW_TEST]
; reps_layers=PriorToLastDictExtractor
reps_layers=Fc78Dict
labeled_pairs_path=./lfw_test_pairs.txt
reps_cache_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/lfw/reps/
comparison_metric=cos
#lfw_dir=../../datasets/lfw-deepfunneled_crops
lfw_dir=../../../datasets/lfw-align-128
reps_results_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/${MODELLING:architecture}/results/

#[REP_BEHAVIOUR]
#activations=True
#activations_dataset=../../datasets/processed/vggface2_discriminator min_size=400_num-classes_1250_{'train': 300, 'val': 50, 'test': 50}_cropsgood_cl/train
#whitelist=["n001974","n006691","n007242","n000620","n002537","n001285","n004569","n008568","n004408","n005164","n000419","n003532","n001145","n007620","n000823","n001775","n007425","n004263","n002298","n003523","n002332","n004265","n003613","n006982","n000692"]
#output_filename=train_activations
#dist_mat=True
#datasets = {
#            "male": "/home/administrator/datasets/dist_mat_dataset_mtcnn/male",
#            "female": "/home/administrator/datasets/dist_mat_dataset_mtcnn/female"
#            }
#comparison_metric=l2
#output_filename=dist_mat
#reduce_performance=False
; output_filename=comparisons_with_fc7_linear_mtcnn_compare
; output_filename=comparisons_with_fc7_linear

#pairs_paths = {
#                "diff_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/diff_pairs.txt",
#                "high_ps_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/high_ps_pairs.txt",
#                "low_ps_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/low_ps_pairs.txt",
#                "same_pairs": "/home/administrator/datasets/high_low_ps_images/image_pairs_lists/same_pairs.txt",
#                "frontal-ref": "/home/administrator/datasets/faces_in_views/frontal_ref.txt",
#                "frontal-quarter_left": "/home/administrator/datasets/faces_in_views/frontal_quarter_left.txt",
#                "frontal-half_left": "/home/administrator/datasets/faces_in_views/frontal_half_left.txt"}
;                 "original-makeup": "/home/administrator/datasets/makeup_insightface/orig-makeup.txt",
;                 "original-ref": "/home/administrator/datasets/makeup_insightface/orig-ref.txt"}
;                 "original-makeup-tight_vertical": "/home/administrator/datasets/makeup_mtcnn_tight_vertical/orig-makeup.txt",
;                 "original-ref-tight_vertical": "/home/administrator/datasets/makeup_mtcnn_tight_vertical/orig-ref.txt",
;                 "original-makeup-tight_horizontal": "/home/administrator/datasets/makeup_mtcnn_tight_horizontal/orig-makeup.txt",
; "half_left-half_right": "/home/administrator/datasets/faces_in_views/half_left-half_right.txt",
;                 "quarter_left-quarter_right": "/home/administrator/datasets/faces_in_views/quarter_left-quarter_right.txt",
;                 "original-ref-tight_horizontal": "/home/administrator/datasets/makeup_mtcnn_tight_horizontal/orig-ref.txt"}
#pairs_image_dirs = {
  #                  "diff_pairs": "/home/administrator/datasets/processed/blurred/blurred_gaus_1/high_ps_low_ps",
  #                  "high_ps_pairs": "/home/administrator/datasets/processed/blurred/blurred_gaus_1/high_ps_low_ps",
  #                  "low_ps_pairs": "/home/administrator/datasets/processed/blurred/blurred_gaus_1/high_ps_low_ps",
  #                  "same_pairs": "/home/administrator/datasets/processed/blurred/blurred_gaus_1/high_ps_low_ps",
  #                  "frontal-ref": "/home/administrator/datasets/processed/blurred/blurred_gaus_1/faces_in_views",
  #                  "frontal-quarter_left": "/home/administrator/datasets/processed/blurred/blurred_gaus_3/faces_in_views",
  #                  "frontal-half_left": "/home/administrator/datasets/processed/blurred/blurred_gaus_3/faces_in_views"}
 #                   #None blurred images:
;                    "diff_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
;                    "high_ps_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
;                    "low_ps_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
;                    "same_pairs": "/home/administrator/datasets/high_low_ps_images/joined",
;                    "frontal-ref": "/home/administrator/datasets/faces_in_views",
;                    "frontal-quarter_left": "/home/administrator/datasets/faces_in_views",
;                    "frontal-half_left": "/home/administrator/datasets/faces_in_views"}
                    ; "half_left-half_right": "/home/administrator/datasets/faces_in_views",
;                     "quarter_left-quarter_right": "/home/administrator/datasets/faces_in_views",
;                     "original-makeup": "/home/administrator/datasets/makeup_insightface/",
;                     "original-ref": "/home/administrator/datasets/makeup_insightface/"}
;                     "original-makeup-tight_vertical": "/home/administrator/datasets/makeup_mtcnn_tight_vertical/",
;                     "original-ref-tight_vertical": "/home/administrator/datasets/makeup_mtcnn_tight_vertical/",
;                     "original-makeup-tight_horizontal": "/home/administrator/datasets/makeup_mtcnn_tight_horizontal/",
;                     "original-ref-tight_horizontal": "/home/administrator/datasets/makeup_mtcnn_tight_horizontal/"}
; pairs_paths = {"frontal-ref": "/home/administrator/datasets/faces_in_views/frontal_ref.txt",
;                 "frontal-quarter_left": "/home/administrator/datasets/faces_in_views/frontal_quarter_left.txt",
;                 "frontal-half_left": "/home/administrator/datasets/faces_in_views/frontal_half_left.txt"
;                 }
; pairs_image_dirs = {"frontal-ref": "/home/administrator/datasets/faces_in_views",
;                     "frontal-quarter_left": "/home/administrator/datasets/faces_in_views",
;                     "frontal-half_left": "/home/administrator/datasets/faces_in_views"
;                     }
#reps_cache_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/pairs/reps/
#reps_results_path=${GENERAL:root_dir}/${GENERAL:experiment_name}/${MODELLING:architecture}/results/

# TODO: Create a standard output folder and format
